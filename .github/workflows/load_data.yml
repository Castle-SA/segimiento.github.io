name: Load Data

on:
  # Schedule to run daily (adjust as needed)
  schedule:
    - cron: '0 0 * * *'  # Every day at midnight (UTC)

      # New trigger for manual runs
  workflow_dispatch:

jobs:
  load_data:
    runs-on: ubuntu-latest  # Specify the runner environment

    steps:
         - uses: actions/checkout@v3  # Checkout repository code (optional)

         - name: Use Node.js 16  # Specify Node.js version
           uses: actions/setup-node@v3
           with:
             node-version: 16

         - name: Install dependencies  # Install required libraries
           run: npm install axios

         - name: Download CSV  # Download data using axios
           run: |
             curl -o data.csv https://docs.google.com/spreadsheets/d/e/2PACX-1vR4E5klg4xrK_-HSTwNy2YHyKGcstOURl43hzeznkIGHodhlqKqhI2u7zOcvQCAl6PcgQ3pNzVXTwrA/pub?gid=1130322350&single=true&output=csv

         - name: Convert CSV to JSON  # Convert data using Papa Parse
           run: |
             node script.js  # Replace with your conversion script

         - name: Push changes  # Push only data.json
           uses: enderzoo/push-to-ftp@v1.0.5
           with:
             connection: ${{ secrets.FTP_CONNECTION }}  # Configure FTP connection details
             destination: /path/to/data.json  # Specify destination path on FTP server
             # Alternatively, use a different push action for GitHub or a cloud storage provider
