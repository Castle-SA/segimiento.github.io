name: Load Data

on:
  # Schedule to run daily (adjust as needed)
  schedule:
    - cron: '0 0 * * *'  # Every day at midnight (UTC)

      # New trigger for manual runs
  workflow_dispatch:

jobs:
  load_data:
    runs-on: ubuntu-latest  # Specify the runner environment

    steps:
      - uses: actions/checkout@v3  # Checkout repository code (optional)

      - name: Use Node.js 16  # Specify Node.js version
        uses: actions/setup-node@v3
        with:
          node-version: 16

      - name: Install Papa Parse  # Library for CSV parsing
        run: npm install papaparse

      - name: Download CSV  # Download data using curl
        run: |
          curl -o data.csv -f https://docs.google.com/spreadsheets/d/e/2PACX-1vR4E5klg4xrK_-HSTwNy2YHyKGcstOURl43hzeznkIGHodhlqKqhI2u7zOcvQCAl6PcgQ3pNzVXTwrA/pub?gid=1130322350&single=true&output=csv

      - name: Check file size  # Verify successful download
        run: ls -l data.csv

      - name: Convert CSV to JSON (example)  # Replace with your conversion logic
        run: |
          if [ -f data.csv ] && [ "$(stat -c%s data.csv)" -gt 0 ]; then
            node -p "require('papaparse').parse(process.stdin.read(), { header: true }).data" < data.csv > data.json
          else
            echo "Error: Failed to download data.csv"
            exit 1
          fi

      - name: Store data.json (optional)  # Persist data within the repository
        uses: actions/upload-artifact@v3
        with:
          name: processed-data
          path: data.json

# This section is commented out as it's not recommended for sensitive data
# - name: Push data.json to FTP (not recommended)  # (replace with your FTP upload logic)
#   uses: (alternative_action_here)  # Replace with a suitable FTP upload action
#   with:
#     # ... FTP connection details
